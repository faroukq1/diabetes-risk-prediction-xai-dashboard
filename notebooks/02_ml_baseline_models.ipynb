{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfc582",
   "metadata": {},
   "source": [
    "## 1. Load Data from Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ca10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the data warehouse\n",
    "conn = sqlite3.connect('../data/diabetes_dwh.db')\n",
    "\n",
    "# Load all data with joins\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    p.patient_id,\n",
    "    p.age,\n",
    "    p.height_cm,\n",
    "    p.weight_kg,\n",
    "    p.bmi,\n",
    "    f.fasting_glucose,\n",
    "    f.hba1c,\n",
    "    rf.sedentary_lifestyle,\n",
    "    rf.family_history,\n",
    "    rf.smoking_status,\n",
    "    rf.diet_quality,\n",
    "    rf.physical_activity,\n",
    "    f.diabetes_diagnosis as target\n",
    "FROM fact_patient_measures f\n",
    "JOIN dim_patient p ON f.patient_id = p.patient_id\n",
    "JOIN dim_risk_factors rf ON f.risk_factor_id = rf.risk_factor_id\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"\\nFeatures: {df.columns.tolist()}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"\\nClass balance: {df['target'].value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43380ffb",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions by class\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "numerical_features = ['age', 'bmi', 'fasting_glucose', 'hba1c', 'weight_kg', 'height_cm']\n",
    "\n",
    "for idx, feature in enumerate(numerical_features):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    df[df['target'] == 0][feature].hist(ax=ax, alpha=0.5, label='Healthy', bins=20, color='green')\n",
    "    df[df['target'] == 1][feature].hist(ax=ax, alpha=0.5, label='Diabetic', bins=20, color='red')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76852b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation = df.drop('patient_id', axis=1).corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "           square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb689990",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "df_fe = df.copy()\n",
    "\n",
    "# Age groups (one-hot encoded)\n",
    "df_fe['age_young'] = (df_fe['age'] < 30).astype(int)\n",
    "df_fe['age_middle'] = ((df_fe['age'] >= 30) & (df_fe['age'] < 50)).astype(int)\n",
    "df_fe['age_senior'] = ((df_fe['age'] >= 50) & (df_fe['age'] < 65)).astype(int)\n",
    "df_fe['age_elderly'] = (df_fe['age'] >= 65).astype(int)\n",
    "\n",
    "# BMI categories\n",
    "df_fe['bmi_underweight'] = (df_fe['bmi'] < 18.5).astype(int)\n",
    "df_fe['bmi_normal'] = ((df_fe['bmi'] >= 18.5) & (df_fe['bmi'] < 25)).astype(int)\n",
    "df_fe['bmi_overweight'] = ((df_fe['bmi'] >= 25) & (df_fe['bmi'] < 30)).astype(int)\n",
    "df_fe['bmi_obese'] = (df_fe['bmi'] >= 30).astype(int)\n",
    "\n",
    "# Glucose categories\n",
    "df_fe['glucose_normal'] = (df_fe['fasting_glucose'] < 100).astype(int)\n",
    "df_fe['glucose_prediabetic'] = ((df_fe['fasting_glucose'] >= 100) & \n",
    "                                (df_fe['fasting_glucose'] < 126)).astype(int)\n",
    "df_fe['glucose_diabetic'] = (df_fe['fasting_glucose'] >= 126).astype(int)\n",
    "\n",
    "# HbA1c categories\n",
    "df_fe['hba1c_normal'] = (df_fe['hba1c'] < 5.7).astype(int)\n",
    "df_fe['hba1c_prediabetic'] = ((df_fe['hba1c'] >= 5.7) & (df_fe['hba1c'] < 6.5)).astype(int)\n",
    "df_fe['hba1c_diabetic'] = (df_fe['hba1c'] >= 6.5).astype(int)\n",
    "\n",
    "# Risk score (composite feature)\n",
    "df_fe['risk_score'] = (\n",
    "    df_fe['sedentary_lifestyle'] * 2 +\n",
    "    df_fe['family_history'] * 3 +\n",
    "    (df_fe['smoking_status'] > 0).astype(int) * 1 +\n",
    "    (df_fe['diet_quality'] == 0).astype(int) * 2 +\n",
    "    (df_fe['physical_activity'] == 0).astype(int) * 2 +\n",
    "    df_fe['bmi_obese'] * 2\n",
    ")\n",
    "\n",
    "# Interaction features\n",
    "df_fe['bmi_x_age'] = df_fe['bmi'] * df_fe['age']\n",
    "df_fe['glucose_x_hba1c'] = df_fe['fasting_glucose'] * df_fe['hba1c']\n",
    "df_fe['lifestyle_score'] = df_fe['sedentary_lifestyle'] + (df_fe['physical_activity'] == 0).astype(int)\n",
    "\n",
    "print(f\"Original features: {df.shape[1]}\")\n",
    "print(f\"After feature engineering: {df_fe.shape[1]}\")\n",
    "print(f\"\\nNew features created: {df_fe.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507c76f",
   "metadata": {},
   "source": [
    "## 4. Prepare Train/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_fe.drop(['patient_id', 'target'], axis=1)\n",
    "y = df_fe['target']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names:\\n{X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 60% train, 20% validation, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp  # 0.25 of 0.8 = 0.2\n",
    ")\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"Train: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nClass distribution in train set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nClass balance in train: {y_train.value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify numerical columns (exclude binary/categorical)\n",
    "numerical_cols = ['age', 'height_cm', 'weight_kg', 'bmi', 'fasting_glucose', \n",
    "                 'hba1c', 'risk_score', 'bmi_x_age', 'glucose_x_hba1c']\n",
    "\n",
    "# Fit on train, transform all sets\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val_scaled[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Save scaler for later use\n",
    "joblib.dump(scaler, '../data/scaler.pkl')\n",
    "\n",
    "print(\"Feature scaling completed\")\n",
    "print(f\"\\nScaled features: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca24651",
   "metadata": {},
   "source": [
    "## 5. Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if class imbalance exists\n",
    "class_counts = y_train.value_counts()\n",
    "imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "\n",
    "print(f\"Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio > 1.5:\n",
    "    print(\"\\nApplying SMOTE to balance classes...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"\\nBefore SMOTE: {X_train_scaled.shape}\")\n",
    "    print(f\"After SMOTE: {X_train_resampled.shape}\")\n",
    "    print(f\"\\nClass distribution after SMOTE:\")\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "else:\n",
    "    print(\"\\nClasses are relatively balanced, no SMOTE needed\")\n",
    "    X_train_resampled = X_train_scaled\n",
    "    y_train_resampled = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80186cdd",
   "metadata": {},
   "source": [
    "## 6. Baseline Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ecbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train_scaled)\n",
    "y_val_pred_rf = rf_model.predict(X_val_scaled)\n",
    "y_test_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Prediction probabilities\n",
    "y_train_proba_rf = rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_val_proba_rf = rf_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"✓ Random Forest training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "def evaluate_model(y_true, y_pred, y_proba, model_name, dataset_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} - {dataset_name} Set\")\n",
    "    print('='*60)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Healthy', 'Diabetic']))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "rf_train_metrics = evaluate_model(y_train, y_train_pred_rf, y_train_proba_rf, \n",
    "                                  \"Random Forest\", \"Train\")\n",
    "rf_val_metrics = evaluate_model(y_val, y_val_pred_rf, y_val_proba_rf, \n",
    "                                \"Random Forest\", \"Validation\")\n",
    "rf_test_metrics = evaluate_model(y_test, y_test_pred_rf, y_test_proba_rf, \n",
    "                                 \"Random Forest\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_rf['feature'][:20], feature_importance_rf['importance'][:20])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance_rf.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bf561",
   "metadata": {},
   "source": [
    "## 7. Baseline Model 2: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a31154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost Classifier...\")\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "xgb_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_scaled)\n",
    "y_val_pred_xgb = xgb_model.predict(X_val_scaled)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Prediction probabilities\n",
    "y_train_proba_xgb = xgb_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_val_proba_xgb = xgb_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_proba_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"✓ XGBoost training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_train_metrics = evaluate_model(y_train, y_train_pred_xgb, y_train_proba_xgb, \n",
    "                                   \"XGBoost\", \"Train\")\n",
    "xgb_val_metrics = evaluate_model(y_val, y_val_pred_xgb, y_val_proba_xgb, \n",
    "                                 \"XGBoost\", \"Validation\")\n",
    "xgb_test_metrics = evaluate_model(y_test, y_test_pred_xgb, y_test_proba_xgb, \n",
    "                                  \"XGBoost\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for XGBoost\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_xgb['feature'][:20], feature_importance_xgb['importance'][:20])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances - XGBoost', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/xgb_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance_xgb.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974eeba0",
   "metadata": {},
   "source": [
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': 'Random Forest', 'Set': 'Train', **rf_train_metrics},\n",
    "    {'Model': 'Random Forest', 'Set': 'Validation', **rf_val_metrics},\n",
    "    {'Model': 'Random Forest', 'Set': 'Test', **rf_test_metrics},\n",
    "    {'Model': 'XGBoost', 'Set': 'Train', **xgb_train_metrics},\n",
    "    {'Model': 'XGBoost', 'Set': 'Validation', **xgb_val_metrics},\n",
    "    {'Model': 'XGBoost', 'Set': 'Test', **xgb_test_metrics}\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('../reports/baseline_models_comparison.csv', index=False)\n",
    "print(\"\\n✓ Comparison saved to ../reports/baseline_models_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcfe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "test_comparison = comparison_df[comparison_df['Set'] == 'Test']\n",
    "\n",
    "# Plot 1: Metrics comparison\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "rf_scores = test_comparison[test_comparison['Model'] == 'Random Forest'][metrics].values[0]\n",
    "xgb_scores = test_comparison[test_comparison['Model'] == 'XGBoost'][metrics].values[0]\n",
    "\n",
    "axes[0].bar(x - width/2, rf_scores, width, label='Random Forest', alpha=0.8)\n",
    "axes[0].bar(x + width/2, xgb_scores, width, label='XGBoost', alpha=0.8)\n",
    "axes[0].set_xlabel('Metrics')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Test Set Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics, rotation=45)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0, 1.1])\n",
    "\n",
    "# Plot 2: ROC Curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_test_proba_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_test_proba_xgb)\n",
    "\n",
    "axes[1].plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={rf_test_metrics[\"roc_auc\"]:.3f})', linewidth=2)\n",
    "axes[1].plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={xgb_test_metrics[\"roc_auc\"]:.3f})', linewidth=2)\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Random Guess', linewidth=1)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curves - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/baseline_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54997686",
   "metadata": {},
   "source": [
    "## 9. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold stratified cross-validation\n",
    "print(\"Performing 5-fold cross-validation...\\n\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Random Forest CV\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, \n",
    "                               cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"Random Forest CV ROC-AUC Scores: {rf_cv_scores}\")\n",
    "print(f\"Mean: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# XGBoost CV\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train_scaled, y_train, \n",
    "                                cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"\\nXGBoost CV ROC-AUC Scores: {xgb_cv_scores}\")\n",
    "print(f\"Mean: {xgb_cv_scores.mean():.4f} (+/- {xgb_cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438d257",
   "metadata": {},
   "source": [
    "## 10. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "joblib.dump(rf_model, '../data/random_forest_model.pkl')\n",
    "joblib.dump(xgb_model, '../data/xgboost_model.pkl')\n",
    "\n",
    "# Save feature names\n",
    "with open('../data/feature_names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(X_train_scaled.columns.tolist()))\n",
    "\n",
    "# Save datasets for next notebooks\n",
    "joblib.dump((X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test), \n",
    "           '../data/processed_datasets.pkl')\n",
    "\n",
    "print(\"✓ Models and datasets saved successfully\")\n",
    "print(\"\\n✓ Part 2.1 (Baseline Models) completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
